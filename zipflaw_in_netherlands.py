# -*- coding: utf-8 -*-
"""ZipfLaw in Netherlands

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rcQR4s1GYl1Sr4w4TvqhC7B3s2V4V-ne

## **Extracting Data from DBPedia**

1. Install and import libraries that will be used to prepare boh hypotheses
"""

!pip install SPARQLWrapper
!pip install scipy

from SPARQLWrapper import SPARQLWrapper, JSON, N3
import csv
import os
import pandas as pd
import matplotlib.pyplot as plt
import regex as re

"""2. Define SPARQL query which extracts wanted data from DBPedia.

"""

# location where the csv will be outputted
csv_location = os.getcwd() + "/output.csv"

# we can add more variables to fetch from DBpedia here

sparql_query = {
    "SELECT": ["?city_name", "?latitude", "?longitude", "?total_pop"],
    "UNION": [
        # {
        #     '?city  rdf:type  yago:WikicatCityCountiesOfPoland': ' ',
        #     'dbo:country  dbr:Poland': ' ',
        #     'foaf:name': '?city_name',
        #     'geo:lat': '?latitude',
        #     'geo:long': '?longitude',
        #     'dbp:populationTotal': '?total_pop',
        # },
        {
            '?city  rdf:type  dbo:City': ' ',
            'dbo:country  dbr:Netherlands': ' ',
            'foaf:name': '?city_name',
            'geo:lat': '?latitude',
            'geo:long': '?longitude',
            'dbp:populationTotal': '?total_pop',
        },
        {
            '?city  rdf:type  dbo:Town': ' ',
            'dbo:country  dbr:Netherlands': ' ',
            'foaf:name': '?city_name',
            'geo:lat': '?latitude',
            'geo:long': '?longitude',
            'dbp:populationTotal': '?total_pop',
        },
        {
            '?city  rdf:type  dbo:Village': ' ',
            'dbo:country  dbr:Netherlands': ' ',
            'foaf:name': '?city_name',
            'geo:lat': '?latitude',
            'geo:long': '?longitude',
            'dbp:populationTotal': '?total_pop',
        }
    ],
}

"""3. Create a function to format and execute the query based on the variables given before"""

def query_data(query_data: dict):

    def format_query(_query_data: dict):
        # create SELECT statement
        _result = '''SELECT DISTINCT'''
        for variable in _query_data["SELECT"]:
            _result += variable + " "
        _result += '\n'

        # create WHERE statement
        _result += "WHERE {\n"
        for union_item in _query_data["UNION"]:

            # process each UNION statement
            _result += "{\n"
            for key, value in union_item.items():
                _result += key + " " + value + " ;\n"
            _result = _result[:-2] + ".\n } UNION "

        _result = _result[:-7] + "}\n"

        # create ORDER BY statement
        _result += '''ORDER BY DESC(?total_pop) '''   # ugly hack

        # create LIMIT statement (used for testing)
        #_result += ''' LIMIT 10 '''

        return _result

    # initialize the wrapper
    sparql = SPARQLWrapper('https://dbpedia.org/sparql')

    # construct and fire the query
    query = format_query(query_data)

    sparql.setQuery(query)

    # parse the result
    sparql.setReturnFormat(JSON)
    qres = sparql.query().convert()

    # digest it
    digested = []
    for result in qres['results']['bindings']:

        entry = {}
        for value in query_data["SELECT"]:
            if value[0] == '?':
                entry[value[1:]] = result[value[1:]]    # extract relevant fields
        digested.append(entry)

    return digested

"""4. Create a function to save the output query data to csv file"""

def output_to_csv(data: list, file_path: str):

    # open file and prepare csv writer
    with open(file_path, 'w', encoding='UTF8') as file:
        writer = csv.writer(file)

        # output headers
        headers = []
        for key in data[0]:
            headers.append(str(key))
        writer.writerow(headers)

        # output data
        for entry in data:
            row = []
            for key, value in entry.items():
                row.append(value["value"])
            writer.writerow(row)

"""5. Running the function to query the data and save the file to csv"""

# fetch digested data
data = query_data(sparql_query)

# save to csv
output_to_csv(data, csv_location)
print(data)

"""6. Preview the csv table that has been created6. Preview the csv table that has been created"""

df_dirty = pd.read_csv('/content/output.csv')
df_dirty.head()

df_dirty.tail()

"""## **Cleaning Data**

1. Remove character from total_pop and convert it to integer
"""

df = df_dirty

for i in range(df['total_pop'].size):
  df['total_pop'][i] = re.sub( '[^0-9]', '', df['total_pop'][i])
  df['total_pop'][i] = int(df['total_pop'][i])

"""2. Filtering row with any NaN values and zero population cities"""

print('Row with NaN values=', df['city_name'].isna().sum())
df[df['city_name'].isnull()]

df = df.replace(0, np.nan)
df = df.dropna(how='any',axis=0) 
df.head()

df.tail()

"""2. Reset index after dropping row"""

df = df.reset_index(drop=True)

df.tail()

"""# **Testing ZipfLaw**

1. Install and import library that will be used
"""

import pandas as pd
import plotly.express as px
import plotly.graph_objects as go

"""2. Sort data by cities population and adds 'rank' column based on cities population"""

sorted_df = df.sort_values(by=["total_pop"], ascending=False)
sorted_df['rank'] = range(1, len(sorted_df) + 1)

sorted_df.head()

max_rank = sorted_df['rank'].max()
lowest_pop = sorted_df.loc[sorted_df['rank'] == max_rank, 'total_pop'].iloc[0]
print('Max rank is', max_rank, ' with total population of ', lowest_pop)
sorted_df.tail()

"""3. Add 'zipf_tot_pop' column as a total population data that follow Zipf's Law """

sorted_df.dtypes

max_pop = sorted_df['total_pop'].max()
sorted_df['zipf_tot_pop'] = max_pop // sorted_df['rank']
sorted_df = sorted_df[['city_name', 'latitude', 'longitude', 'rank', 'total_pop', 'zipf_tot_pop']]
sorted_df.head(20)

"""3. Create plot-graph"""

fig = px.line(sorted_df, x = 'rank', y = 'total_pop' , 
title='Cities in Netherlands based on their Rank', log_x=True,log_y=True)

fig.update_traces(name='Netherlands\'s Cities', showlegend = True)
fig.add_scatter(x = sorted_df['rank'], y = sorted_df['zipf_tot_pop'], name='ZipfLaw')


fig.show()

"""4. Calculating RMSE and R (correlation coefficient) of plotted graph"""

import numpy as np 
import sklearn.metrics as metrics

rms = metrics.mean_squared_error(sorted_df['total_pop'], sorted_df['zipf_tot_pop'], squared=False)
print('Root mean square of the graph is', rms)

r2 = metrics.r2_score(sorted_df['total_pop'], sorted_df['zipf_tot_pop'])
print('The correlation coefficient or R2 is', r2)

"""5. Calculating Hellinger Distance and  Kullback-Leiber Divergence //It has to be in frequenct distribution (?)"""

clasf_df = sorted_df
clasf_df['diff'] = clasf_df['total_pop'] - clasf_df['zipf_tot_pop']
clasf_df['prob_pop'] = clasf_df['total_pop'] / np.sum(clasf_df['total_pop'])
clasf_df['prob_zip'] = clasf_df['zipf_tot_pop'] / np.sum(clasf_df['zipf_tot_pop'])
clasf_df.head(5)

np.sum(clasf_df['prob_zip'])

clasf_df['norm_freq'] = 1/(clasf_df['rank'] * (np.sum(1/clasf_df['total_pop'])))
clasf_df.head(5)

def hel_dist(true, pred):
  return np.sqrt(0.5 * np.sum((np.sqrt(true) - np.sqrt(pred)) ** 2))

def kul_lei(true, pred):
  return -(np.sum(true * (np.log10(pred / true))))

print('Helinger Distance (P || Q):', hel_dist(clasf_df['prob_pop'], clasf_df['prob_zip']))
print('Helinger Distance (Q || P):', hel_dist(clasf_df['prob_zip'], clasf_df['prob_pop']))
print('Kullback-Leiber Divergence (P || Q) :', kul_lei(clasf_df['prob_pop'], clasf_df['prob_zip']))
print('Kullback-Leiber Divergence (Q || P) :', kul_lei(clasf_df['prob_zip'], clasf_df['prob_pop']))

print('Helinger Distance :', hel_dist(clasf_df['prob_zip'], clasf_df['prob_pop']))
print('Kullback-Leiber Divergence :', kul_lei(clasf_df['prob_zip'], clasf_df['prob_pop']))

data_std = sorted_df['total_pop'].std()
data_mean = sorted_df['total_pop'].mean()

zipf_std = sorted_df['zipf_tot_pop'].std()
zipf_mean = sorted_df['zipf_tot_pop'].mean()

print("Data mean: {}, Data std: {}".format(data_mean,data_std))
print("Zipf mean: {}, Zipf std: {}".format(zipf_mean,zipf_std))

"""# **Classify Cities**

1. Classifying cities by total population based on BDSPR
"""

bbsr_conditions = [
    (clasf_df['total_pop'] < 5000),
    (clasf_df['total_pop'] >= 5000) & (clasf_df['total_pop'] < 10000),
    (clasf_df['total_pop'] >= 10000) & (clasf_df['total_pop'] < 20000),
    (clasf_df['total_pop'] >= 20000) & (clasf_df['total_pop'] < 50000),
    (clasf_df['total_pop'] >= 50000) & (clasf_df['total_pop'] < 100000),
    (clasf_df['total_pop'] >= 100000)
    ]

bbsr_values = ['Rural community', 'Small town', 'Large-small town', 'Small-Medium town',
               'Large-Medium town', 'Large cities']

clasf_df['bbsr_class'] = np.select(bbsr_conditions, bbsr_values)
clasf_df.head(5)

clasf_df['bbsr_class'].value_counts()

"""2. Visualize Result"""

clasf_df['bbsr_class'].value_counts().plot(kind='barh')

df_LC = clasf_df[clasf_df.bbsr_class == 'Large cities']
df_LST = clasf_df[clasf_df.bbsr_class == 'Large-small town']
df_SMT = clasf_df[clasf_df.bbsr_class == 'Small-Medium town']
df_LMT = clasf_df[clasf_df.bbsr_class == 'Large-Medium town']
df_ST = clasf_df[clasf_df.bbsr_class == 'Small town']
df_RC = clasf_df[clasf_df.bbsr_class == 'Rural community']

fig = go.Figure(go.Bar(x = df_LC['diff'], y = df_LC['city_name'], orientation='h'))
fig.update_layout(title='Difference population of large cities in Poland to Zipf scenario')
fig.show()

fig = go.Figure(go.Bar(x = df_LMT['diff'], y = df_LMT['city_name'], orientation='h'))
fig.update_layout(title='Difference population of large medium town in Poland to Zipf scenario')
fig.show()

fig = go.Figure(go.Bar(x = df_SMT['diff'], y = df_SMT['city_name'], orientation='h'))
fig.update_layout(title='Difference population of small medium town in Poland to Zipf scenario')
fig.show()

fig = go.Figure(go.Bar(x = df_LST['diff'], y = df_LST['city_name'], orientation='h'))
fig.update_layout(title='Difference population of large small town in Poland to Zipf scenario')
fig.show()

fig = go.Figure(go.Bar(x = df_ST['diff'], y = df_ST['city_name'], orientation='h'))
fig.update_layout(title='Difference population of small town in Poland to Zipf scenario')
fig.show()